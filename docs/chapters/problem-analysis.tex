The goal of this chapter is to give a clear idea of why the project was needed,
who is impacted by the project and how it stands in relation to other projects.
First, we look at user story.
Secondly, we consider three cases of other companies that have solved
a similar problem and explain how they relate to our own project. % add links to relevant parts
Then we describe the stakeholders and assess the ethical implications of our project.
Finally, we take a look at some potential bottlenecks we could have run into.


\section{Problem statement}\label{sec:problem-statement}
During our first meeting with Mr. Kahawati from Avonic, we have identified the problem statement as follows:

Avonic would like to make it easier to record educational sessions by creating
a camera that follows the speaker as they move around in a room. The way they want to do
this is by using a camera at the back of the room that automatically tracks the speaker.
Avonic has already tried to do this using just the visual information of the camera, but
it turned out not to be enough to accurately track speakers in all cases:
multiple people may look like the speaker by moving or opening their mouths,
while only one person is actually speaking.

To solve this problem, Avonic wants to try to use a microphone in addition
to the camera to identify the speaker. A common setup would be to have
the camera in the back of the room and the microphone in the front above the speaker(s).
In order to explore this solution, Avonic has asked us to spend
ten weeks working on a system that tracks a speaker using both a camera and a
microphone. The camera we have to use is the Avonic CM70 model
(figure \ref{fig:camera}) and the
microphone is the Sennheiser TeamConnect Ceiling 2 (figure \ref{fig:microphone}).
We are not allowed to
reprogram these devices. That is why a single-board computer, the Nvidia Jetson Nano,
has to be used to communicate with the camera and microphone through application programming
interfaces (APIs). Moreover, it should be easy for a user to start the system
and it should not require any technical knowledge.

To recap:
using the camera, microphone and single-board computer mentioned above,
we had to find a way to automatically move to camera to point at a speaker after minimal installation.

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
    \centering
    \includegraphics[width=.7\linewidth]{camera}
    \captionof{figure}{Avonic CM70 camera}
    \label{fig:camera}
\end{minipage}%
\begin{minipage}{.5\textwidth}
    \centering
    \includegraphics[width=.7\linewidth]{microphone}
    \captionof{figure}{Sennheiser TeamConnect Ceiling 2 microphone}
    \label{fig:microphone}
\end{minipage}
\end{figure}

\section{Available solutions}\label{sec:available-solutions}
We now discuss three different solutions that are already available for
customers. These products were created by companies other than Avonic to solve
a similar problem to the one described in
\hyperref[sec:problem-statement]{Section 2.1}. Looking at such products helps to get a
better idea of the state of the art. For every case below, we contrast the
solution with Avonic’s vision and explain how it relates to the project we
worked on.

\paragraph{AVer}\mbox{} \\
AVer created a camera that can ``automatically track a presenter’s face and
movements''\cite{aver-camera}. The camera stands alone and is not helped by an
external microphone. Instead, it has a so-called ``dual-lens design'' that
allows to keep a secondary panorama view while zooming in on the speaker. In
this way, new speakers can still be recognized when they are not recorded by
the zoomed in lens.

Though Avonic has tried to use a dual-lens design before, our project is about
using a single camera with a single lens. To make up for the lack of multiple
lenses, we have to use a microphone. This way it is still possible to detect
new speakers that are not in view of the camera. The video processing
techniques used by AVer may be similar to the ones employed by Avonic, but
since the microphone was an essential part of our project, the AVer camera
could not serve as a good source of inspiration.

\paragraph{Yealink}\mbox{} \\
On top of a dual-lens design similar to the one AVer used, the Yealink camera
has a built-in microphone array which helps to localize the sound and track the
speaker\cite{yealink-camera}. As audio from a microphone array is used to
detect the speaker's location, this is similar to our project.

The big difference is that the Yealink microphone is built into the camera,
which eliminates the need to translate data from the microphone to the camera.
Since we have a seperate microphone at a different position from the camera, we
face an entirely different problem from Yealink.

\paragraph{Cisco}\mbox{} \\
Using one camera, Cisco locates the speaker and zooms in on that speaker, while
another camera is watching the entire room to look for the next
speaker\cite{cisco-camera}. This dual-camera approach helps to switch quickly
between different speakers. It can be compared to the dual-lens design used by
AVer and Yealink; all these products have an option to search for a new speaker
while recording the active speaker.

The use of two cameras thus makes it easier for Cisco to localize the speaker.
The overall problem is in this way made less complex. Avonic wants to use only
one camera and one microphone and try to track speakers as well as companies
like Cisco do with two or more cameras.

\medskip
As we can see, the most common approach to the speaker localization problem is
to use a dual-lens or dual-camera design. On behalf of Avonic, we experimented
with a new approach: one camera and one microphone. This poses new problems.
Our devised solution is described in \hyperref[ch:solution]{Chapter 4}.

\section{Stakeholders}\label{sec:stakeholders}
This section describes who the stakeholders of our project are and how we
considered their interests during the ten week process. The definition of
stakeholder that we are going to use is as follows: “All those who have an
interest in the system and who will eventually be responsible for its
acceptance”\cite{stakeholder-definition}. Using this definition, we identified
four main types of stakeholders. These people are directly affected by the
result of our project. The types of stakeholders of our project are as follows:

\paragraph{Presenters}\mbox{} \\
People who participate in lectures or conferences using MaAT have a high
interest in the quality of the speaker tracking. They want their activity to be
well recorded. If the speaker tracking is not correct or not smooth, these
stakeholders will not be satisfied with the product. The accuracy of the
tracking is most important to them.

\paragraph{IT staff}\mbox{} \\
The IT people who are going to set up MaAT want the process of setting up the
system to be quick and easy. It should not require hours of experimenting to
figure out how to get the tracking started. The setup process should also not
require any specific technical knowledge. We tested the simplicity of the setup
process by asking other people like Mr. Van der Voort to try to set up MaAT
without any guidance.

\paragraph{Developers}\mbox{} \\
Developers could be building upon our code in the future. Since we write our
code for Avonic, we expect this category to include only their developers. It is
important to the developers that the code is well written and well documented.
Some of the criteria we used to determine whether code is well written are test
coverage, readability and extensibility. These criteria and more are explained
in \hyperref[ch:workflow]{chapter 5} where we talk about the
workflow.

\paragraph{Avonic}\mbox{} \\
Avonic as a company has a say in the requirements of our project. They have the
general picture in mind, considering both the clients and the developers. It is
important to them that the compromises made in the process are carefully
considered and explained. This includes a clear and elaborate report that
explains precisely what steps have been taken to reach the conclusion. Such a
report can be used by Avonic to decide whether they want to continue to build on
our product.

\paragraph{Satisfaction of all stakeholders}\mbox{} \\
In order to satisfy every stakeholder as much as possible, we continually
talked to people from Avonic. We had weekly meetings with Ali Kahawati, one of
the software developers at the company, and visited the office three times a
week to be able to talk with other employees as well. Throughout the project,
this helped to stay in touch with the wants of the stakeholders. We had no
direct contact with the clients, so this group was mainly represented by the
Avonic team.


\section{Possible pitfalls}\label{sec:possible-pitfalls}
At the start of the project, we identified two possible risks which we needed to
decide on how to avert. As these risks threatened to slow down our progress, we
tried to reduce their impact as much as possible. We list these risks below.

\subsection{Access to hardware}
The largest risk was access to the hardware (or lack thereof). Since our
project relies on the availability of both the camera and microphone, we would
have been unable to work on it without them. The contact person from Avonic --
Mr. Kahawati -- informed us that we would only be able to come to the office
three days a week, which could have prevented us from working on the project
on the other days.

We were allowed to bring a camera home to test, but that was not an option for
the large and expensive ceiling microphone. We mitigated this by using a
virtual private network (VPN) connection to the office. This way we had a way
to access the microphone remotely, although we could not test it very well when
nobody from the group was at the office.

Apart from the camera and the microphone, we also needed an NVIDIA Jetson Nano
to run our software. This device became available during the eighth week of the
project, which caused some new problems to appear in our code. Up until that
point we had used our own computers to simulate the production environment.
Despite the risk of having too little time to fix new bugs, the last two weeks
turned out to be enough to make the core of MaAT work on the Jetson Nano.

\subsection{Work space}
During the project we could visit the office at most three days a week. This
meant that we did not always have a place to work together as a group. Group
meetings required a quiet meeting room, which we were not always able to find.
On the days that we were not able to go to the office, we tried to find a room
on the TU Delft campus. Whenever we were not able to get a meeting room, we
went to a public place on campus. In such places, we could still have meetings
and we could still work closely together. All our meetings with Mr. Kahawati
happened on days we could visit the office, so those meetings did not suffer
from our limited time at the office.

\section{Ethical implications}
We investigated the ethical implications by looking at five categories of
ethical risks. We discuss all of these categories in
\hyperref[ch:ethics-appendix]{Appendix A - Ethical implications}. In the current
section, we summarize our findings.

We concluded that our tracker does not have any true ethical risks. Any
unethical actions for which our tracker can be used, could also be done by using
a smartphone; often in a more effective way. This includes things like
surveillance and the spreading of personal data. Though it is possible to use
our tracker to collect personal data without permission, it will be hard to do
so: the microphone and the camera are difficult to hide and they need to be
correctly calibrated. Because of this, we do not expect our tracker to be used
in any unethical way.
