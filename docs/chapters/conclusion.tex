Our task was to develop a speaker tracker using the Avonic CM70 camera and the
Sennheiser TeamConnect Ceiling 2 microphone. We did so by creating four
different tracking models that are useful in different scenarios: the preset
model works best when speakers are only present in a few locations; the audio
tracking model acts best in scenarios where speakers do not change the height of
their locations; the two object-audio tracking models combined with object
tracking work best in cases where there are little to no restrictions on how
speakers can move. This system of using different models allows Avonic or any
other developers to easily integrate their own models into our system.

To facilitate all of the above-mentioned tracking models, an API was developed
for the camera and microphone to communicate with the hardware that is used for
tracking. Additionally, to accommodate users with different levels of knowledge,
a Flask application with web interface was developed. It allows to access all
of the camera and microphone API's features, calibrate and control the flow of
tracking models. The web interface also provides the user with additional
information for better understanding of the current state of the system --
visualization of the camera’s and the microphone’s directions and footage
streamed from the camera. The APIs and the web UI can be distributed as separate
packages that would allow engineers at to Avonic easily integrate our solution with
their modifications.

Together with this report we delivered the code base with extensive
documentation of its files and instructions on how to run it.
Because of our workflow practices, the software is tested with 89\% line coverage
and 62\% mutation coverage. These high test coverages ensure the correctness of the
code and protect against new bugs when new code is added to the project in the
future.

In the future multiple things can be improved, which can vary from an
engineering-only to research-related tasks. Actual dependency injection can be
created for cleaner code. Models can be improved with new models for adaptive speed and zoom.
To make the object tracking faster, YOLO could be ported to TensorRT.
New object-audio tracking strategies could be developed for
smoother movement of the camera. Finally, a new algorithm could be created for
calculating the distance between the microphone and the speaker. However, this
first requires access to the individual microphones in the microphone array.
